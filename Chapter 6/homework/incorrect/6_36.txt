セット・アソシアティブ・キャッシュ C

x[0][i] = x[1][i];

src 0

ダイレクトマップ
E = 1

cache size 512 bytes
block size 16 bytes 4つの値を保存できる

S = 512 / 16 = 32

0
~	cache index 0
16
~	cache index 1
32
~	cache index 2
48
~	cache index 3
64
...
496
~ cache index 31
512

x[0][0] ~ x[0][128] 0 ~ 512 cache in
x[1][0] ~ x[1][128] 0 ~ 512 cache in

A.
1

B.
x[0][0] ~ x[0][128] 0 ~ 512 cache in
x[1][0] ~ x[1][128] 512 ~ 1024 cache in


cache index 512 / 16 = 32
sum read 256
64 / 256 = 1/4

C.
E = 2
LRU(least recentry used)

S = 512 / 16 / 2 = 16

1セットあたりのバイト数 = 16 * 2 = 32

32 / 4 = 8個の配列を保存できる

x[0][0] ~ x[0][128] 0 ~ 512 cache in
x[1][0] ~ x[1][128] 0 ~ 512 cache in

x[0][0] ~ x[0][7]	0 ~ 32		setindex 0
x[0][8] ~ x[0][15] 	32 ~ 64		setindex 1
x[0][16] ~ x[0][23]	64 ~ 96		setindex 2
x[0][24] ~ x[0][31]	96 ~ 128	setindex 3

x[1][0] ~ x[1][7] 0 ~ 32 setindex 4

x[0][0] setindex 0
x[1][0] setindex 1
x[0][1] setindex 0
x[1][1] setindex 1

128 / 8 = 16  x[y]のミス数
16 * 2 = 32

sum read 256

32 / 256 = 1/8

D.
否
cacheを増やすということはsetindexを増やすことになる。
しかしLRUポリシーはsetindexは関係なく最近使われたものを消すのでミス率は変わらない。

E.
減る
ブロックサイズを増やすと1回の読み込みで多くのデータを読み込めるのでミス率が減る。


answer
C.
セット・アソシアティブ・キャッシュでのLPUポリシーはラインをリプレースするので、16bytesしか読み込まない。
よって、128 / 4 = 32 で、 32*2 = 64, 64 / 256 = 1/4 となる。

